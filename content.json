{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"regular_expression","slug":"regular-expression","date":"2025-04-16T10:17:00.000Z","updated":"2025-04-16T13:04:53.619Z","comments":true,"path":"2025/04/16/regular-expression/","permalink":"http://example.com/2025/04/16/regular-expression/","excerpt":"","text":"正则表达式指南元字符: . ^ 表示匹配其中任意一个字符，与相同，在中的元字符与普通字符无异。放在字符前的将匹配除之外的所有字符，在其他位置没有特殊含义。如果是在字符串的开头，则为从开头匹配字符串。同匹配行的末尾,或者后跟换行符的任意位置。同\\Z\\b字边界，仅在单词开头或结尾。\\B相反，不在字边界。 转义字符,\\和[分别表示匹配\\和[。有一些很有用的预定义字符集合由\\开头： \\d匹配任何十进制数字=[0-9] \\D匹配任何非数字字符=[^0-9] \\s匹配任何空白字符=[\\t\\n\\r\\f\\v],\\S相反 \\w匹配任何字母与数字字符=[a-zA-Z0-9_],\\W相反 .匹配除换行符之外的任何字符 重复元字符,指定前一个字符可以匹配零次或更多次。 +表示匹配一次或更多次 ？表示匹配一次或零次重复的匹配是贪婪的，会尽可能多的匹配，在不符合时回退。{m,n}其中m,n都是十进制整数，表示必须至少重复m次，最多重复n次。缺省时，m会解释为最少重复零次，n会解释为最多重复无数次。{m}只完全匹配m次由以上内容可知：={0，}，+={1，}，？={0，1} 12&gt;&gt;&gt; import re&gt;&gt;&gt; p = re.compile('ab*',re.IGNORECASE) r前缀表示反斜杠不以任何特殊方式处理前缀为r的字符串字面。举两个可能帮助理解的例子，如果想要匹配\\，那么先让需要转义为\\，这作为匹配的内容，在传给python时需要让结果仍为\\，则需要两次转义为\\，而使用r’\\‘就可以保证传入的为\\字面值。如果要找到\\b匹配的值，需要传入r’\\b’因为\\b不能被正确识别为正则表达式,而会识别为退格。可以简单记为除了’ab’这样的简单匹配外建议用r’’。 12345&gt;&gt;&gt; p = re.compile('[a-z]+')&gt;&gt;&gt; m = p.match('tempo') #返回一个匹配对象&lt;re.Match object;span=(0,5),match='tempo'&gt;&gt;&gt;&gt; m.group() #返回正则匹配的字符串 'tempo'&gt;&gt;&gt; m.start(),m.end() (0,5)&gt;&gt;&gt; m.span() (0,5) match()确定正则是否从字符串开头匹配，search()扫描字符串，找到此正则匹配的任何位置，findall()找到正则匹配的所有子字符串，并作为列表返回，finditer()同上返回为一个iterator； 编译标志ASCII, A 使几个转义如 \\w、\\b、\\s 和 \\d 匹配仅与具有相应特征属性的 ASCII 字符匹配。 DOTALL, S 使 . 匹配任何字符，包括换行符。 IGNORECASE, I 进行大小写不敏感匹配。 LOCALE, L 进行区域设置感知匹配。 MULTILINE, M 多行匹配，影响 ^ 和 $。 VERBOSE, X （为 ‘扩展’） 启用详细的正则，可以更清晰，更容易理解。 分组分组用’(‘’)’来标记，包含的表达式为一组。子组从左到右按照左括号顺序编号： 123456&gt;&gt;&gt; p = re.compile('(a(b)c)d')&gt;&gt;&gt; m = p.match('abcd')&gt;&gt;&gt; m.group(0)&gt;&gt;&gt; 'abcd'&gt;&gt;&gt; m.group(2)&gt;&gt;&gt; 'b' \\1后向引用允许你指定还必须在字符串中的当前位置找到先前捕获组的内容。例如，以下正则检测字符串中重复的单词。: 123p = re.compile(r'\\b(\\w+)\\s+\\1\\b')p.search('Paris in the the spring').group()'the the' 非捕获和命名组","categories":[],"tags":[]},{"title":"machine_learning","slug":"machine-learning","date":"2025-04-02T17:29:12.000Z","updated":"2025-04-08T11:26:57.363Z","comments":true,"path":"2025/04/03/machine-learning/","permalink":"http://example.com/2025/04/03/machine-learning/","excerpt":"","text":"预测器，回归器或者自变量X中被加入了一列，这样就将截距式进行了转化。则作为结果，因变量。被称为误差项，噪声，这一部分代表了所有只影响y但与x无关的因素。估计的过程被称为从训练数据学习，目的有两个方面：（1）解释：理解y与x之间的关系；（2）预测：学习预测y。 逻辑回归考虑一个含n训练样本的数据集，由p个自变量组成，Y{0，1}是一个布尔符号： 我们假设任意维都与条件独立； 假设那么有logit的逆sigmoid 表示一组训练样本， 代表真实标签，正确估计的概率为： 那么所有样本估计正确的概率为：取log后得到log-likelihood：那么maximum likelihood就是寻找合适的 ,并且 分类任务在分类任务的语境下，我们一般用来表示。对应着的样本被称为正样本，反之则成为负样本。我们称为分类器，是在上的投影，因此 是表示了正负样本间差别的方向，因此应该与正样本同向，与负样本反向，也就是从负样本指向正样本。由之前的推导可以得到： 感知机感知机可以表示为,这里的w，b合在一起相当于： 三种模型生成模型生成模型是X与Y联合概率分布的统计模型，进行条件推理： 协方差矩阵X是一个n*p的矩阵，代表第k个样本的第i个特征 有以下性质: ，其中A是一个矩阵，b是一个向量 判别模型判别模型对Y在得到X条件下的条件概率建模，即，一般有softmax层的判别模型可表示为：其中表示经过k层神经网络后的输出，。 描述模型描述模型目标是描述的分布,可以表示为 Loss function为了训练得到，我们需要定义 最小二乘 线性回归相较于最小二乘回归，线性回归的值受到异常值影响更小。 逻辑回归根据之前的推导我们用negative loglikelihood作为损失函数而对于，的情况，则有：这个损失函数称为logistic loss。 用于分类的Loss函数 以上的损失函数都基于,我们称为间的margin。如果那么我们希望预测结果非常偏向正的，反之希望预测结果非常偏向负的。 最小二乘我们要求,可以对其求一阶导数，导数为0时有：在特殊情况下，如果X是正交归一的，这是可以简化为其中X是np的，是p1的，y是n*1的。对投影的推导,假设a在b上的投影为eb,e为一标量： 通过上面的推导，可以看到实际上是Y在X的列空间上的投影：残差表示了无法被当前模型表达的信息。 的分布假设存在一个真正的模型,则：假设,则可以求得： KL距离与交叉熵（略）最大似然辨别模型通过最大化下式来训练:由大数定律，在n足够大的情况下：前者为常数相对应的，生成或描述模型的最大似然则是通过对的估计。 梯度下降是学习率，是梯度，是某一步时的参数。 梯度下降算法：随机梯度下降：从n个样本中随机选择一个样本计算梯度Mini-batch:随机选择一个小批量，用其平均梯度作为梯度: 关于学习率：根据Robbins-Monroe theory我们通常要求：(1)(2)第一条保证算法可以达到最值，而第二条保证算法不会从最小值跳出。在实际情况中，我们会有更复杂的机制，比如在一定轮后减小学习率，在错误率稳定后缩小学习率等。 Momentum：包含有momentum机制的梯度下降,这一机制将之前的梯度作为后来梯度的一部分,下图中左半为随机梯度下降，右半为包含了momentum机制的随机梯度下降:Adagrad：不同参数的梯度可能是不同的，adagrad为每个参数自适应地调整学习率，用梯度除以梯度的平方和，可以让调整次数较少的参数更快学习，反之避免更新过快。是一个很小的数（比如）可以防止除0。RMSprop使用以下的机制：手动设置，因此,可以看到越靠前的梯度被递减越多。Adam优化器结合了RMSprop和momentum的机制： log-likelihood的梯度具有softmax层的判别模型:对于判别模型如果y=k(当y的真实标签是k)，则：这里的Y是独热矢量 batch_size并非越大越好在不考虑运算成本的情况下，将n个样本的梯度平均后学习不如将一定大小batch的样本梯度平均后学习。在小batch时，学习得到的梯度是有一定误差的，可以帮助跳出局部最小值。 langevinBrownian motion：其中如果将分为n段，,此时：在这种情况下：可以看到t足够小的情况下，速度趋近于无穷大。Langevin dynamic在训练过程中，则有我们需要手动改变的就是与。 LDA(Linear Discriminant Analysis)检验是否数据是线性可分的 support vectr machine(支持向量机)margin and support vectors对于逻辑回归:可以看到若 &gt;&gt; 0,此时p趋近于1，模型会预测为y=1；反之p趋近于0，模型高概率预测为0，但是当时，模型的预测结果会对噪声非常敏感。 对于分类任务：我们令,若且则我们可以自信地说说代表了一个正样本，反之则是自信的负样本。逻辑回归也可以转化为分类，比如神经元,因此下面统一讨论。我们假设代表的w和b都扩大三倍，显然并不会让样本的符号产生变化，因此我们对w进行归一化：因此修正偶的margin：此时可以证明，，位于边界上，因此可以衡量到边界的距离。在所有的训练样本中，我们应更关注于最有分类难度的部分，也就是那些有最小margin的。 margin classifier让我们假设所有分类器都达到了100%的准确度，那么如何衡量分类器的好坏？我们的目标是：这样让margin尽可能大,也就是。在之前的部分，我们选择控制w=1，但在实际情况中，我们选择控制而不是w来简化计算，因为改变w不会影响分类结果。我们假设。上面的优化条件变成了: Lagrange multipliers${min}w f(w) s.t. h_k(w)=0,k=1,2,…,K应用乘子法：L(w,\\lambda)=f(w)+\\sum{k=1}^K\\lambda_kh_k(w)最小值取在\\frac{\\partial L}{\\partial w}=0,\\forall k,\\frac{\\partial L}{\\partial\\lambda_k}=0$拉格朗日乘子法:h(w)=0上对w求导都为0，否则稍作移动h(w)就不为0，同时f(w)的最值取在导数为0的点。乘子的引入，对L以求导保证了h(w)=0，对L以w求导则保证了为f的极值点，因此可以求出f的最值。接下来考虑更普遍的情况：考虑如果g(w)&gt;0或者h(w)不等于0，则V(w)=+,即：","categories":[],"tags":[]},{"title":"traffic_analysis","slug":"traffic-analysis","date":"2025-04-02T17:19:36.000Z","updated":"2025-04-02T17:19:36.461Z","comments":true,"path":"2025/04/03/traffic-analysis/","permalink":"http://example.com/2025/04/03/traffic-analysis/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2025-04-02T15:30:40.626Z","updated":"2025-04-02T15:30:40.626Z","comments":true,"path":"2025/04/02/hello-world/","permalink":"http://example.com/2025/04/02/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[]}